# -*- coding: utf-8 -*-
"""HW_digits_recognition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kTuEwrbR14IVdb11yDccgkWaLrralEZ7
"""

#Base libraries
from keras.datasets import mnist
import matplotlib.pyplot as plt
import numpy as np

#preprocessing libraries
from keras.utils import to_categorical
from tensorflow.keras.preprocessing.image import ImageDataGenerator

#NN libraries
from keras.models import Sequential, load_model
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout
from keras.initializers import HeNormal
from keras.optimizers import Adam
from keras.losses import CategoricalCrossentropy

from keras.callbacks import EarlyStopping

from keras.regularizers import l2

#Load mnist dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()

x_train.shape, y_train.shape, x_test.shape, y_test.shape

#converting target data to categorical values
Y_train = to_categorical(y_train)
Y_test = to_categorical(y_test)

#Intialize objects for model processing
initializer = HeNormal()
adam_optimizer = Adam()
category_loss = CategoricalCrossentropy()

early_stopping = EarlyStopping(
    monitor='val_accuracy',
    patience=3,
    restore_best_weights=True
)

#CNN Model Arichtecture
model = Sequential()
model.add(Conv2D(input_shape = (x_train.shape[1], x_train.shape[2], 1), filters = 32, kernel_size= (3,3), padding = 'same', activation = 'relu', kernel_regularizer=l2(0.001)))
model.add(MaxPooling2D(pool_size = (2,2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(units = 100, activation='relu', kernel_regularizer=l2(0.001)))
model.add(BatchNormalization())
model.add(Dropout(0.5))
model.add(Dense(units = 10, activation='softmax'))

model.compile(optimizer = adam_optimizer, loss = category_loss, metrics = ['accuracy'])

history = model.fit(x_train, Y_train, batch_size=100, epochs=50, validation_data= (x_test, Y_test), callbacks=[early_stopping], verbose=1)

model.evaluate(x_train, Y_train)
model.evaluate(x_test, Y_test)

np.argmax(model.predict(x_test), axis = 1)

model.save('model.h5')

!pip install streamlit streamlit-drawable-canvas

!pip install tensorflow

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# from streamlit_drawable_canvas import st_canvas
# import tensorflow as tf
# from tensorflow.keras.models import load_model
# import numpy as np
# import cv2
# from PIL import Image
# 
# st.title("üñåÔ∏è Hand written Digit Detection")
# 
# @st.cache_resource
# def load_digit_model():
#     return load_model("model.h5")
# 
# model_loaded = load_digit_model()
# 
# # Debug
# st.write("Model input shape expected:", model_loaded.input_shape)
# 
# # canvas parameters
# canvas_result = st_canvas(
#     fill_color="rgba(255, 165, 0, 0.3)",  # opacity
#     stroke_width=3,
#     stroke_color="#000",
#     background_color="#eee",
#     height=300,
#     width=500,
#     drawing_mode="freedraw",
#     key="canvas",
# )
# 
# confidence_threshold = 0.5
# 
# def preprocess_image(img):
#   """Preprocess image for digit detection"""
#   # Convert to grayscale
#   gray = cv2.cvtColor(img.astype("uint8"), cv2.COLOR_RGBA2GRAY)
# 
#   # Apply Gaussian blur to reduce noise
#   #blurred = cv2.GaussianBlur(gray, (5, 5), 0)
# 
#   # Apply adaptive thresholding
#   thresh_image = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)
# 
#   return thresh_image, gray
# 
# def segment_digits(thresh_image):
#   """Segment individual digits from the image"""
#   # Find contours
#   contours, _ = cv2.findContours(thresh_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
# 
#   # Filter contours first, then sort by x-coordinate (left to right)
#   valid_contours = []
# 
#   for contour in contours:
#     # Filter out very small contours (noise)
#     if cv2.contourArea(contour) < 100:
#       continue
# 
#     # Get bounding rectangle
#     x, y, w, h = cv2.boundingRect(contour)
# 
#     # Filter by size and aspect ratio
#     if w > 15 and h > 15 and w < 200 and h < 200:
#       aspect_ratio = w / h
#       if 0.2 <= aspect_ratio <= 3.0:
#         valid_contours.append((contour, x, y, w, h))
# 
#   # FIXED: Sort by x-coordinate (left to right) instead of area
#   valid_contours.sort(key=lambda item: item[1])  # Sort by x-coordinate
# 
#   digit_images = []
#   bounding_boxes = []
# 
#   for contour in contours:
#     # Get bounding rectangle
#     x, y, w, h = cv2.boundingRect(contour)
# 
#     # Filter out very small contours (noise)
#     if cv2.contourArea(contour) < 100:  # Add minimum area filter
#       continue
# 
#     # slightly larger minimum size
#     if w > 15 and h > 15 and w < 200 and h < 200:
#       # Calculate aspect ratio
#       aspect_ratio = w / h
# 
#       # Filter based on aspect ratio (digits are usually taller than wide)
#       if 0.2 <= aspect_ratio <= 3.0:
#         # Check for overlapping bounding boxes (remove duplicates)
#         overlap = False
#         for existing_x, existing_y, existing_w, existing_h in bounding_boxes:
#           # Check if current box significantly overlaps with existing ones
#           if (abs(x - existing_x) < 20 and abs(y - existing_y) < 20):
#             overlap = True
#             break
# 
#         if not overlap:
#           digit_roi = thresh_image[y:y+h, x:x+w]
#           pad = 10
#           padded = cv2.copyMakeBorder(digit_roi, pad, pad, pad, pad, cv2.BORDER_CONSTANT, value=0)
#           resized = cv2.resize(padded, (28, 28), interpolation=cv2.INTER_AREA)
# 
#           digit_images.append(resized)
#           bounding_boxes.append((x, y, w, h))
# 
#   return digit_images, bounding_boxes
# 
# def predict_digits(digit_images):
#   """Predict digits from segmented images"""
#   if not digit_images:
#     return []
# 
#   # Preprocess for model
#   processed_digits = []
#   for digit in digit_images:
#     # Try inverting colors - MNIST has white digits on black background
#     inverted = 255 - digit
# 
#     # Normalize
#     normalized = inverted.astype('float32') / 255.0
#     #normalized = digit.astype('float32') / 255.0
#     processed_digits.append(normalized)
# 
#   processed_digits = np.array(processed_digits)
# 
#   #adds channel dimension
#   processed_digits = processed_digits.reshape(-1, 28, 28, 1)
#   #processed_digits = np.expand_dims(processed_digits, axis=0)
# 
#   # DEBUG: Show what the model receives
#   st.write("Model input shapes:", processed_digits.shape)
#   st.write("Model input range:", processed_digits.min(), "to", processed_digits.max())
# 
#   # Show processed digits that go to the model
#   st.write("Processed digits sent to model:")
#   if len(processed_digits) > 0:
#     cols = st.columns(len(processed_digits))
#     for i, digit in enumerate(processed_digits):
#       with cols[i]:
#         # FIXED: Remove channel dimension for display (28, 28, 1) -> (28, 28)
#         display_img = digit.squeeze()  # This removes the channel dimension
#         st.image(display_img, caption=f"Model Input {i+1}", width=100, clamp=True)
# 
# 
#   # Make predictions
#   predictions = model_loaded.predict(processed_digits)
#   predicted_classes = np.argmax(predictions, axis=1)
#   confidence_scores = np.max(predictions, axis=1)
# 
#   # DEBUG: Show raw predictions
#   st.write("Raw prediction probabilities:")
#   for i, pred in enumerate(predictions):
#     st.write(f"Digit {i+1} probabilities:")
#     for class_idx, prob in enumerate(pred):
#       st.write(f"  Class {class_idx}: {prob:.4f}")
#     st.write(f"  Predicted: {predicted_classes[i]} (confidence: {confidence_scores[i]:.4f})")
#     st.write("---")
# 
#   return list(zip(predicted_classes, confidence_scores))
# 
# if st.button('Submit'):
#   if canvas_result.image_data is not None:
#     # capture RGBA image
#     img = canvas_result.image_data
# 
#     #Preporcessing
#     threshold_image, original_gray = preprocess_image(img)
# 
#     #Segmenting digits
#     digits, bounding_boxes = segment_digits(threshold_image)
# 
#     # DEBUG: Show how many digits were found
#     st.write(f"Number of digits detected: {len(digits)}")
#     st.write(f"Bounding boxes: {bounding_boxes}")
# 
#     #DEBUG:
#     #DEBUG: Show segmented digits
#     if len(digits) > 0:
#       st.write("Final processed images sent to model:")
#       cols = st.columns(len(digits))
#       for i, digit in enumerate(digits):
#         with cols[i]:
#          # FIXED: digit is already 2D (28, 28), no need to squeeze
#          st.image(digit, caption=f"Digit {i+1}", width=100, clamp=True)
# 
#     st.write("Bounding boxes (should be left to right):")
#     for i, bbox in enumerate(bounding_boxes):
#         x, y, w, h = bbox
#         st.write(f"Digit {i+1}: x={x}, y={y} (leftmost should have smallest x)")
# 
#     # DEBUG : show which segmented digit is which:
#     st.write("Segmented digits in order:")
#     cols = st.columns(len(digits))
#     for i, (digit, bbox) in enumerate(zip(digits, bounding_boxes)):
#         with cols[i]:
#             x, y, w, h = bbox
#             st.image(digit, caption=f"Position x={x}", width=100)
# 
#     # DEBUG : show which segmented digit is which:
#     if len(digits) > 0:
#       st.write("Segmented digits in order:")
#       cols = st.columns(len(digits))
#       for i, (digit, bbox) in enumerate(zip(digits, bounding_boxes)):
#         with cols[i]:
#           x, y, w, h = bbox
#           st.image(digit, caption=f"Position x={x}", width=100, clamp=True)
# 
#     # DEBUG : Show the thresholded image to verify segmentation
#     st.image(threshold_image, caption="Thresholded Image", width=300)
# 
#     # Predict digits
#     predictions = predict_digits(digits)
# 
#     # Filter by confidence
#     results = []
#     for i, (pred_class, confidence) in enumerate(predictions):
#       if confidence >= confidence_threshold:
#         x, y, w, h = bounding_boxes[i]
#         results.append({
#             'digit': pred_class,
#             'confidence': confidence,
#             'bbox': (x, y, w, h)
#         })
# 
#     # Sort by x-coordinate (left to right)
#     results.sort(key=lambda x: x['bbox'][0])
# 
#     # Display the prediction result
#     st.subheader("Prediction")
#     st.write(f"The predicted number is: {''.join(map(str, [r['digit'] for r in results]))}")  # Assuming the model returns a single prediction

!wget -q -O - ipv4.icanhazip.com

!streamlit run app.py & npx localtunnel --port 8501